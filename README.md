# LingCloud
This project(LingCloud 1.0) aims to attach human-like eyes to the large language model.

Background
GPT-4's understanding of images has reached an unprecedented level. For us (without a lot of computing resources and financial support), is it possible to connect visual information to the large language model (brain) and increase its understanding of the external objective world (infinite-granularity visual content) understanding? Yes! such as BLIP-2 and others. So, how to do this has become a very significant research direction.

## How to do?

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vcr1data:\n",
    "-------------\n",
    "#### Data sample:\n",
    "\n",
    "##### Data sample in vcr_qa.json:\n",
    "| Key       | Value                                                        |\n",
    "| --------- | ------------------------------------------------------------ |\n",
    "| image_id  | vcr-0                                                        |\n",
    "| img_fn    | lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg |\n",
    "| task_type | QA                                                           |\n",
    "| question  | Does person feel comfortable ?                               |\n",
    "| answer    | No she does not .                                            |\n",
    "##### Data sample in vcr_mutil-choice.json:\n",
    "| Key           | Value                                                             |\n",
    "| --------------| ------------------------------------------------------------------|\n",
    "| image_id      | vcr-0                                                             |    \n",
    "| img_fn        | lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg |\n",
    "| task_type     | multi-choice                                                      |\n",
    "| answers       | ['Yes because the person sitting next to her is smiling . ', 'No she does not . ', 'Yes , she is wearing something with thin straps . ', 'Yes , she is cold . '] |                                                                                |\n",
    "| answer_label  | 1                                                                 |\n",
    "-------------\n",
    "#### Data numbers:\n",
    "| Data json             | Number                                                            |\n",
    "| ----------------------| ------------------------------------------------------------------|\n",
    "| vcr_qa.json           | 212923                                                            |\n",
    "| vcr_mutil-choice      | 212923                                                            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'vcr-0', 'img_fn': 'lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'task_type': 'QA', 'question': 'Does person feel comfortable ? ', 'answer': 'No she does not . '}\n",
      "{'image_id': 'vcr-0', 'img_fn': 'lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'task_type': 'multi-choice', 'question': 'Does person feel comfortable ? ', 'answers': ['Yes because the person sitting next to her is smiling . ', 'No she does not . ', 'Yes , she is wearing something with thin straps . ', 'Yes , she is cold . '], 'answer_label': 1}\n",
      "212923\n",
      "212923\n",
      "['vcr1images/', 'vcr1images/movieclips_But_Who_Measured_the_First_Hill_SCENE_-_The_Englishman_Who_Went_Up_a_Hill_But_Came_Do..._MOVIE/', 'vcr1images/movieclips_But_Who_Measured_the_First_Hill_SCENE_-_The_Englishman_Who_Went_Up_a_Hill_But_Came_Do..._MOVIE/fDA85m3v2TA@2.json', 'vcr1images/movieclips_But_Who_Measured_the_First_Hill_SCENE_-_The_Englishman_Who_Went_Up_a_Hill_But_Came_Do..._MOVIE/fDA85m3v2TA@2.jpg', 'vcr1images/movieclips_But_Who_Measured_the_First_Hill_SCENE_-_The_Englishman_Who_Went_Up_a_Hill_But_Came_Do..._MOVIE/fDA85m3v2TA@9.jpg', 'vcr1images/movieclips_But_Who_Measured_the_First_Hill_SCENE_-_The_Englishman_Who_Went_Up_a_Hill_But_Came_Do..._MOVIE/fDA85m3v2TA@0.json', 'vcr1images/movieclips_But_Who_Measured_the_First_Hill_SCENE_-_The_Englishman_Who_Went_Up_a_Hill_But_Came_Do..._MOVIE/fDA85m3v2TA@9.json', 'vcr1images/movieclips_But_Who_Measured_the_First_Hill_SCENE_-_The_Englishman_Who_Went_Up_a_Hill_But_Came_Do..._MOVIE/fDA85m3v2TA@0.jpg', 'vcr1images/movieclips_Play_It_Again_Sam/', 'vcr1images/movieclips_Play_It_Again_Sam/kF-KLIi97Uc@16.jpg', 'vcr1images/movieclips_Play_It_Again_Sam/WdfgoDKArzM@8.jpg', 'vcr1images/movieclips_Play_It_Again_Sam/kF-KLIi97Uc@16.json', 'vcr1images/movieclips_Play_It_Again_Sam/Z-Vnk_VTtzk@4.jpg', 'vcr1images/movieclips_Play_It_Again_Sam/kF-KLIi97Uc@14.jpg', 'vcr1images/movieclips_Play_It_Again_Sam/au5XE48PEeU@6.json', 'vcr1images/movieclips_Play_It_Again_Sam/au5XE48PEeU@8.json', 'vcr1images/movieclips_Play_It_Again_Sam/B8CGtuR9FnY@10.json', 'vcr1images/movieclips_Play_It_Again_Sam/B8CGtuR9FnY@10.jpg', 'vcr1images/movieclips_Play_It_Again_Sam/B8CGtuR9FnY@12.json', 'vcr1images/movieclips_Play_It_Again_Sam/8JkLimZnZAs@19.json']\n"
     ]
    }
   ],
   "source": [
    "# vcr1data\n",
    "import os\n",
    "import json\n",
    "\n",
    "root_path = \"/root/data/mutimodel_dataset/data_split/vcr1data_over/\"\n",
    "\n",
    "with open(os.path.join(root_path, \"raw_json/vcr_qa.json\"), \"r\") as f:\n",
    "    qa_file_content = f.read()\n",
    "\n",
    "with open(os.path.join(root_path, \"raw_json/vcr_mutil-choice.json\"), \"r\") as f:\n",
    "    choice_file_content = f.read()\n",
    "\n",
    "with open(os.path.join(root_path, \"raw_json/chunk_belong.json\"), \"r\") as f:\n",
    "    chunk_belong = f.read()\n",
    "\n",
    "\n",
    "chunk_belong_dict = json.loads(chunk_belong)\n",
    "qa_json_data = json.loads(qa_file_content)\n",
    "choice_json_data = json.loads(choice_file_content)\n",
    "print(qa_json_data[0])\n",
    "print(choice_json_data[0])\n",
    "print(len(qa_json_data))\n",
    "print(len(choice_json_data))\n",
    "\n",
    "import zipfile\n",
    "\n",
    "def list_files_in_zip(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "        file_list = zip_file.namelist()\n",
    "    return file_list\n",
    "\n",
    "zip_file_list = list_files_in_zip(os.path.join(root_path, \"image/chunk1.zip\"))\n",
    "print(zip_file_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'Does person feel comfortable ? ', 'answer': 'No she does not . ', 'image_path': 'vcr1images/lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'chunk_belong': 'chunk5.zip'}, {'query': 'Do person work together ? ', 'answer': 'Yes they do . ', 'image_path': 'vcr1images/lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'chunk_belong': 'chunk5.zip'}, {'query': 'Do person know each other ? ', 'answer': 'Yes they do . ', 'image_path': 'vcr1images/lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'chunk_belong': 'chunk5.zip'}, {'query': 'What is person feeling right now ? ', 'answer': 'He is feeling amused . ', 'image_path': 'vcr1images/lsmdc_3038_ITS_COMPLICATED/3038_ITS_COMPLICATED_00.08.14.616-00.08.17.313@0.jpg', 'chunk_belong': 'chunk2.zip'}, {'query': 'Why is person smiling at person ? ', 'answer': 'person has spinach in her teeth . ', 'image_path': 'vcr1images/lsmdc_3038_ITS_COMPLICATED/3038_ITS_COMPLICATED_00.08.14.616-00.08.17.313@0.jpg', 'chunk_belong': 'chunk2.zip'}, {'query': 'Where are person ? ', 'answer': 'They are at a restaurant . ', 'image_path': 'vcr1images/lsmdc_3038_ITS_COMPLICATED/3038_ITS_COMPLICATED_00.08.14.616-00.08.17.313@0.jpg', 'chunk_belong': 'chunk2.zip'}, {'query': 'Why is person laying down ? ', 'answer': 'They were pushed down . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.10.26.133-02.10.30.224@0.jpg', 'chunk_belong': 'chunk7.zip'}, {'query': 'What is person doing ? ', 'answer': 'Cheering on the fighters . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.10.26.133-02.10.30.224@0.jpg', 'chunk_belong': 'chunk7.zip'}, {'query': 'Was person involved in the whole fight ? ', 'answer': 'No they were not . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.10.26.133-02.10.30.224@0.jpg', 'chunk_belong': 'chunk7.zip'}, {'query': 'What is person about to do ? ', 'answer': 'They are opening up a note . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.21.22.023-02.21.30.292@2.jpg', 'chunk_belong': 'chunk7.zip'}]\n"
     ]
    }
   ],
   "source": [
    "# qa data\n",
    "qa_json_data_output = []\n",
    "\n",
    "for qa_data in qa_json_data:\n",
    "    query = qa_data['question']\n",
    "    answer = qa_data['answer']\n",
    "    image_path = 'vcr1images/' + qa_data['img_fn']\n",
    "    chunk_belong = chunk_belong_dict[image_path]\n",
    "    \n",
    "    qa_json_data_output.append({\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"image_path\": image_path,\n",
    "        \"chunk_belong\": chunk_belong,\n",
    "    })\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data_qa.json\"), 'w') as f:\n",
    "    f.write(json.dumps(qa_json_data_output))\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data_qa.json\"), 'r') as f:\n",
    "    print(json.loads(f.read())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'Does person feel comfortable ? A. Yes because the person sitting next to her is smiling . B. No she does not . C. Yes , she is wearing something with thin straps . D. Yes , she is cold . ', 'answer': 'D. No she does not . ', 'image_path': 'vcr1images/lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'chunk_belong': 'chunk5.zip'}, {'query': 'Do person work together ? A. No they do not . B. Yes , person are walking together and are clearly dressed up in office wear . C. Yes they do . D. Yes , person are both security guards . ', 'answer': 'D. Yes they do . ', 'image_path': 'vcr1images/lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'chunk_belong': 'chunk5.zip'}, {'query': 'Do person know each other ? A. No . they do not know each other . B. No , person is taking person out of car . C. Yes they do . D. No , person are adversaries . ', 'answer': 'D. Yes they do . ', 'image_path': 'vcr1images/lsmdc_3015_CHARLIE_ST_CLOUD/3015_CHARLIE_ST_CLOUD_00.23.57.935-00.24.00.783@0.jpg', 'chunk_belong': 'chunk5.zip'}, {'query': 'What is person feeling right now ? A. He is feeling despair . B. He is confused and can not believe what he is hearing person tell him . C. He is feeling pretty scared . D. He is feeling amused . ', 'answer': 'D. He is feeling amused . ', 'image_path': 'vcr1images/lsmdc_3038_ITS_COMPLICATED/3038_ITS_COMPLICATED_00.08.14.616-00.08.17.313@0.jpg', 'chunk_belong': 'chunk2.zip'}, {'query': 'Why is person smiling at person ? A. person has given her some spare change . B. She is happy to see him happy . C. person has spinach in her teeth . D. person complimented how she looks . ', 'answer': 'D. person has spinach in her teeth . ', 'image_path': 'vcr1images/lsmdc_3038_ITS_COMPLICATED/3038_ITS_COMPLICATED_00.08.14.616-00.08.17.313@0.jpg', 'chunk_belong': 'chunk2.zip'}, {'query': 'Where are person ? A. person are in a basement . B. They are in a workshop . C. person are in the airport . D. They are at a restaurant . ', 'answer': 'D. They are at a restaurant . ', 'image_path': 'vcr1images/lsmdc_3038_ITS_COMPLICATED/3038_ITS_COMPLICATED_00.08.14.616-00.08.17.313@0.jpg', 'chunk_belong': 'chunk2.zip'}, {'query': 'Why is person laying down ? A. person has fallen ill . B. They were pushed down . C. person is relaxing after a long day . D. person is being interrogated by person . ', 'answer': 'D. They were pushed down . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.10.26.133-02.10.30.224@0.jpg', 'chunk_belong': 'chunk7.zip'}, {'query': 'What is person doing ? A. person is buying something . B. Cheering on the fighters . C. person is leaving the room after talking with person . D. person is doing a ballroom dance with person . ', 'answer': 'D. Cheering on the fighters . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.10.26.133-02.10.30.224@0.jpg', 'chunk_belong': 'chunk7.zip'}, {'query': 'Was person involved in the whole fight ? A. Yes , it appears that person may die in this fight . B. No person is betting on the opponent . C. No they were not . D. No , person did not start the fire . ', 'answer': 'D. No they were not . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.10.26.133-02.10.30.224@0.jpg', 'chunk_belong': 'chunk7.zip'}, {'query': 'What is person about to do ? A. person is about to play hockey . B. person is about to go inside the building . C. They are opening up a note . D. person is about to wake person . ', 'answer': 'D. They are opening up a note . ', 'image_path': 'vcr1images/lsmdc_1051_Harry_Potter_and_the_goblet_of_fire/1051_Harry_Potter_and_the_goblet_of_fire_02.21.22.023-02.21.30.292@2.jpg', 'chunk_belong': 'chunk7.zip'}]\n"
     ]
    }
   ],
   "source": [
    "# choice data\n",
    "option_list = ['A. ', 'B. ', 'C. ', 'D. ', 'E. ', 'F. ', 'G. ', 'H. ']\n",
    "choice_json_data_output = []\n",
    "\n",
    "for choice_data in choice_json_data:\n",
    "    query = choice_data['question']\n",
    "    answers = choice_data['answers']\n",
    "    answer_index = choice_data['answer_label']\n",
    "    for index, label in enumerate(answers):\n",
    "        query += option_list[index] + label\n",
    "    answer = option_list[index] + answers[answer_index]\n",
    "\n",
    "    image_path = 'vcr1images/' + choice_data['img_fn']\n",
    "    chunk_belong = chunk_belong_dict[image_path]\n",
    "    \n",
    "    choice_json_data_output.append({\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"image_path\": image_path,\n",
    "        \"chunk_belong\": chunk_belong,\n",
    "    })\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data_choice.json\"), 'w') as f:\n",
    "    f.write(json.dumps(choice_json_data_output))\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data_choice.json\"), 'r') as f:\n",
    "    print(json.loads(f.read())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scienceqa:\n",
    "-------------\n",
    "#### Data sample:\n",
    "\n",
    "##### Data sample in scienceqa_scienceqa.json:\n",
    "\n",
    "| Key       | Value                                                        |\n",
    "| --------- | ------------------------------------------------------------ |\n",
    "| image_id  | science-1                                                    |\n",
    "| task_type | scienceQA                                                    |\n",
    "| question  | Which of these states is farthest north?                     |\n",
    "| choices   | ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma']        |\n",
    "| answer    | 0                                                            |\n",
    "| lecture   | Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\\nA compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\\nThe north arrow points to the North Pole. On most maps, north is at the top of the map.  |\n",
    "-------------\n",
    "#### Data numbers:\n",
    "| Data json                             | Number                                                            |\n",
    "| --------------------------------------| ------------------------------------------------------------------|\n",
    "| scienceqa_scienceqa.json              | 6218                                                              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'science-1', 'task_type': 'scienceQA', 'question': 'Which of these states is farthest north?', 'choices': ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma'], 'answer': 0, 'lecture': 'Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\\nA compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\\nThe north arrow points to the North Pole. On most maps, north is at the top of the map.'}\n",
      "6218\n",
      "['train/', 'train/21045/', 'train/21045/image.png', 'train/4535/', 'train/4535/image.png', 'train/18285/', 'train/18285/choice_0.png', 'train/18285/choice_1.png', 'train/12930/', 'train/12930/image.png', 'train/1576/', 'train/1576/image.png', 'train/6566/', 'train/6566/choice_0.png', 'train/6566/choice_1.png', 'train/6566/image.png', 'train/12019/', 'train/12019/image.png', 'train/6649/', 'train/6649/image.png']\n"
     ]
    }
   ],
   "source": [
    "# scienceqa\n",
    "import os\n",
    "import json\n",
    "\n",
    "root_path = \"/root/data/mutimodel_dataset/data_split/scienceqa/\"\n",
    "\n",
    "with open(os.path.join(root_path, \"raw_json/scienceqa_scienceqa.json\"), \"r\") as f:\n",
    "    choice_file_content = f.read()\n",
    "\n",
    "with open(os.path.join(root_path, \"raw_json/chunk_belong.json\"), \"r\") as f:\n",
    "    chunk_belong = f.read()\n",
    "\n",
    "\n",
    "chunk_belong_dict = json.loads(chunk_belong)\n",
    "choice_json_data = json.loads(choice_file_content)\n",
    "\n",
    "print(choice_json_data[0])\n",
    "print(len(choice_json_data))\n",
    "\n",
    "import zipfile\n",
    "\n",
    "def list_files_in_zip(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "        file_list = zip_file.namelist()\n",
    "    return file_list\n",
    "\n",
    "zip_file_list = list_files_in_zip(os.path.join(root_path, \"image/chunk1.zip\"))\n",
    "print(zip_file_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Which of these states is farthest north? A. West Virginia B. Louisiana C. Arizona D. Oklahoma', 'answer': ' D. West Virginia', 'image_path': 'train/1/image.png', 'chunk_belong': 'chunk1.zip', 'lecture': 'Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\\nA compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\\nThe north arrow points to the North Pole. On most maps, north is at the top of the map.'}\n"
     ]
    }
   ],
   "source": [
    "# choice data\n",
    "option_list = [' A. ', ' B. ', ' C. ', ' D. ', ' E. ', ' F. ', ' G. ', ' H. ']\n",
    "choice_json_data_output = []\n",
    "\n",
    "for choice_data in choice_json_data:\n",
    "    query = choice_data['question']\n",
    "    answers = choice_data['choices']\n",
    "    answer_index = choice_data['answer']\n",
    "    for index, label in enumerate(answers):\n",
    "        query += option_list[index] + label\n",
    "    answer = option_list[index] + answers[answer_index]\n",
    "    lecture = choice_data['lecture']\n",
    "\n",
    "    image_path = 'train/' + choice_data['image_id'].replace('science-', '') + '/image.png'\n",
    "    chunk_belong = chunk_belong_dict[image_path]\n",
    "    \n",
    "    choice_json_data_output.append({\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"image_path\": image_path,\n",
    "        \"chunk_belong\": chunk_belong,\n",
    "        \"lecture\": lecture,\n",
    "    })\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data_choice.json\"), 'w') as f:\n",
    "    f.write(json.dumps(choice_json_data_output))\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data_choice.json\"), 'r') as f:\n",
    "    print(json.loads(f.read())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minigpt4_qa:\n",
    "-------------\n",
    "#### Data sample:\n",
    "\n",
    "##### Data sample in minigpt4_qa.json:\n",
    "| Key       | Value                                                        |\n",
    "| --------- | ------------------------------------------------------------ |\n",
    "| image_id  | minigpt4-2                                                   |\n",
    "| data_type | QA                                                           |\n",
    "| question  |  Who or what is shown in the image?                          |\n",
    "| answer    |  The image shows a man fishing on a lawn next to a river with a bridge in the background.   |\n",
    "\n",
    "-------------\n",
    "#### Data numbers:\n",
    "| Data json                             | Number                                                            |\n",
    "| --------------------------------------| ------------------------------------------------------------------|\n",
    "| minigpt4_qa.json                      | 17195                                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 'minigpt4-2', 'data_type': 'QA', 'question': ' Who or what is shown in the image? ', 'answer': ' The image shows a man fishing on a lawn next to a river with a bridge in the background.'}\n",
      "17195\n",
      "['image/', 'image/3006.jpg', 'image/1920.jpg', 'image/2893.jpg', 'image/4698.jpg', 'image/4917.jpg', 'image/1992.jpg', 'image/201.jpg', 'image/268.jpg', 'image/3809.jpg', 'image/349.jpg', 'image/1373.jpg', 'image/3498.jpg', 'image/1694.jpg', 'image/4956.jpg', 'image/4528.jpg', 'image/4908.jpg', 'image/1487.jpg', 'image/3284.jpg', 'image/4532.jpg']\n"
     ]
    }
   ],
   "source": [
    "# minigpt4_qa\n",
    "import os\n",
    "import json\n",
    "\n",
    "root_path = \"/root/data/mutimodel_dataset/data_split/minigpt4/\"\n",
    "\n",
    "with open(os.path.join(root_path, \"raw_json/minigpt4_qa.json\"), \"r\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "with open(os.path.join(root_path, \"raw_json/chunk_belong.json\"), \"r\") as f:\n",
    "    chunk_belong = f.read()\n",
    "\n",
    "\n",
    "chunk_belong_dict = json.loads(chunk_belong)\n",
    "json_data = json.loads(file_content)\n",
    "\n",
    "print(json_data[0])\n",
    "print(len(json_data))\n",
    "\n",
    "import zipfile\n",
    "\n",
    "def list_files_in_zip(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "        file_list = zip_file.namelist()\n",
    "    return file_list\n",
    "\n",
    "zip_file_list = list_files_in_zip(os.path.join(root_path, \"image/chunk1.zip\"))\n",
    "print(zip_file_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': ' Who or what is shown in the image? ', 'answer': ' The image shows a man fishing on a lawn next to a river with a bridge in the background.', 'image_path': 'image/2.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' What can be seen on the other side of the river? ', 'answer': ' Trees can be seen on the other side of the river.', 'image_path': 'image/2.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' What is the weather like in the image? ', 'answer': ' The sky is cloudy in the image.', 'image_path': 'image/2.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' What can be seen in the background of the image? ', 'answer': ' A bridge can be seen in the background of the image.', 'image_path': 'image/2.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' Where is the man fishing in the image? ', 'answer': ' The man is fishing on a lawn next to a river in the image.', 'image_path': 'image/2.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' What material are the countertops made of in the kitchen?', 'answer': ' The countertops in the kitchen are made of black granite.', 'image_path': 'image/3.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' What kind of appliances are there in the kitchen?', 'answer': ' The kitchen has stainless steel appliances, including a refrigerator, oven, and dishwasher.', 'image_path': 'image/3.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' What is the color of the backsplash behind the stove in the kitchen?', 'answer': ' The backsplash behind the stove in the kitchen is white in color.', 'image_path': 'image/3.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' What is the color of the walls in the kitchen?', 'answer': ' The walls in the kitchen are painted white.', 'image_path': 'image/3.jpg', 'chunk_belong': 'chunk1.zip'}, {'query': ' Is there a door in the kitchen that leads to the outside?', 'answer': ' Yes, there is a door in the kitchen that leads to the outside.', 'image_path': 'image/3.jpg', 'chunk_belong': 'chunk1.zip'}]\n"
     ]
    }
   ],
   "source": [
    "# qa data\n",
    "json_data_output = []\n",
    "\n",
    "for data in json_data:\n",
    "    query = data['question']\n",
    "    answer = data['answer']\n",
    "    image_path = 'image/' + '{}.jpg'.format(data['image_id'].replace('minigpt4-', ''))\n",
    "    chunk_belong = chunk_belong_dict[image_path]\n",
    "    \n",
    "    json_data_output.append({\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"image_path\": image_path,\n",
    "        \"chunk_belong\": chunk_belong,\n",
    "    })\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data.json\"), 'w') as f:\n",
    "    f.write(json.dumps(json_data_output))\n",
    "\n",
    "with open(os.path.join(root_path, \"json/data.json\"), 'r') as f:\n",
    "    print(json.loads(f.read())[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmeye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
